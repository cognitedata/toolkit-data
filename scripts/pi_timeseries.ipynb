{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from string import Template\n",
    "\n",
    "import yaml\n",
    "\n",
    "from cognite.client import CogniteClient, global_config\n",
    "\n",
    "file_path = Path(\"cognite-sdk-config.yaml\")\n",
    "\n",
    "# Read in yaml file and substitute environment variables in the file string\n",
    "env_sub_template = Template(file_path.read_text())\n",
    "file_env_parsed = env_sub_template.substitute(dict(os.environ))\n",
    "\n",
    "# Load yaml file string into a dictionary to parse global and client configurations\n",
    "cognite_config = yaml.safe_load(file_env_parsed)\n",
    "\n",
    "# If you want to set a global configuration it must be done before creating the client\n",
    "global_config.apply_settings(cognite_config[\"global\"])\n",
    "client = CogniteClient.load(cognite_config[\"client\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after drop: ['external_id', 'name', 'is_step', 'description', 'unit', 'compdev', 'location5', 'pointtype', 'convers', 'descriptor', 'digitalset', 'zero', 'filtercode', 'compdevpercent', 'compressing', 'tag', 'srcptid', 'displaydigits', 'recno', 'excdev', 'userreal2', 'userreal1', 'totalcode', 'ptclassname', 'typicalvalue', 'pointid', 'pointsource', 'location1', 'location2', 'location3', 'location4', 'shutdown', 'compmin', 'ptclassrev', 'scan', 'userint2', 'userint1', 'excdevpercent', 'archiving', 'instrumenttag', 'compmax', 'ptclassid', 'squareroot', 'sourcetag', 'excmin', 'exdesc', 'future', 'excmax', 'step', 'engunits', 'span', '_replicatedSource', '_replicatedTime', '_replicatedInternalId']\n"
     ]
    }
   ],
   "source": [
    "from cognite.client.data_classes import TimeSeriesList\n",
    "import pandas as pd\n",
    "\n",
    "def dump_timeseries_to_csv(timeseries_list: TimeSeriesList, filename: str) -> None:\n",
    "    # Convert TimeSeriesList to a pandas DataFrame\n",
    "    df = timeseries_list.to_pandas(\n",
    "    # Expand the metadata column (assumed to be a dictionary) into separate columns\n",
    "    metadata_df = df['metadata'].apply(pd.Series)\n",
    "\n",
    "    # Combine the original DataFrame with the expanded metadata\n",
    "    df = pd.concat([df.drop(columns=['metadata']), metadata_df], axis=1)\n",
    "\n",
    "     # Remove all columns that start with 'context'\n",
    "    df = df.loc[:, ~df.columns.str.startswith('context')]\n",
    "\n",
    "    columns_to_drop = ['id', 'asset_id', 'created_time', 'last_updated_time', 'is_string', 'security_categories']\n",
    "\n",
    "    # Drop the specified columns\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    print(\"Columns after drop:\", df.columns.tolist())\n",
    "\n",
    "\n",
    "    # Write the resulting DataFrame to a CSV file\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "\n",
    "\n",
    "ts : TimeSeriesList = client.time_series.list(limit=-1, external_id_prefix=\"pi:\")\n",
    "dump_timeseries_to_csv(ts, \"pi.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cognite-toolkit-za48Olhr-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
